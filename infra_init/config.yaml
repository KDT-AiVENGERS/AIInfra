# member_name: eui-jin

data:
  data_dir: "./"
  batch_size: 64
  pred_batch_size: 32
  train_ratio: 0.6

models:
  CNNModel:
    _target_: "__main__.CNNModel"
    type: small

task:
  num_classes: 10
  optimizer:
    _target_: "torch.optim.AdamW"
    lr: 2e-5
  lr_scheduler:
    scheduler:
      _target_: "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts"
      T_0: 50
      T_mult: 2
      verbose: False

    interval: epoch

train:
  # name: my_model_5

  callbacks:
    checkpoint_callback:
      monitor: "val_avg_acc"
      # dirpath: "checkpoints/checkpoints/"
      filename: "best-model-{epoch:02d}-{val_acc:.2f}"
      save_top_k: 1
      save_last: True
      mode: "max"
    early_stop_callback:
      monitor: "val_avg_acc"
      min_delta: 0.01
      patience: 3
      verbose: False
      mode: "max"

  logger:
    # ----- tensorboard -----
    # _target_: pytorch_lightning.loggers.TensorBoardLogger
    # save_dir: tb_logs
    # name: my_model
    # ----- Wandb -----
    _target_: pytorch_lightning.loggers.WandbLogger
    save_dir: log
    project: wandb_test

  trainer:
    max_epochs: 2

sweep:
  method: "bayes"
  metric:
    name: "val_avg_acc"
    goal: "maximize"
  parameters:
    batch_size:
      values: [32, 64, 128]
    type:
      values: ["small", "large"]
  early_terminate:
    type: "hyperband"
    min_iter: 3
  run_cap: 15
