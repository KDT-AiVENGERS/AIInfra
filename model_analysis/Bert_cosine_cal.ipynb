{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12491, 3840])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. embedding vector 텐서 파일 불러와서 shape 확인 : torch.Size([12491, 3840])\n",
    "concatenated_embedding_vectors = torch.load('../data/JobDescription/tensor_data.pth')\n",
    "concatenated_embedding_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. url 가져와서 텐서와 붙이는 함수 정의\n",
    "def vector_with_url(tensor):\n",
    "    url = pd.read_csv('../data/JobDescription/pre_result.csv')['출처 URL']\n",
    "    vector_with_url = {}\n",
    "    for row in range(len(url)):\n",
    "        vector_with_url[url[row]] = tensor[row]\n",
    "    return vector_with_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. URL 쌍 간의 코사인 유사도를 계산하여 DataFrame을 생성하는 함수 정의\n",
    "def cos_similarity_df(data):\n",
    "    url1_list = []\n",
    "    url2_list = []\n",
    "    cos_list = []\n",
    "\n",
    "    # 모든 URL 쌍에 대해 코사인 유사도 계산\n",
    "    for url1, tensor1 in data.items():\n",
    "        for url2, tensor2 in data.items():\n",
    "            if url1 != url2: # 자기 자신과의 계산은 뺍니다!\n",
    "                url1_list.append(url1)\n",
    "                url2_list.append(url2)\n",
    "                cosine_similarity = torch.cosine_similarity(tensor1, tensor2, dim=0)\n",
    "                cos_list.append(cosine_similarity.item())\n",
    "\n",
    "    # DataFrame 생성\n",
    "    df = pd.DataFrame({\n",
    "        'url1': url1_list,\n",
    "        'url2': url2_list,\n",
    "        'cosine-similarity': cos_list\n",
    "    })\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3개 데이터로만 TEST해본 결과 잘 돌아갑니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 벡터에 url을 붙여줍니다.\n",
    "new_embedding_vectors = vector_with_url(concatenated_embedding_vectors)\n",
    "new_embedding_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://www.wanted.co.kr/wd/167436': tensor([-0.0482, -0.0684,  0.1829,  ..., -0.2828,  0.1753,  0.2709]),\n",
       " 'https://www.wanted.co.kr/wd/167433': tensor([ 0.0370, -0.0011,  0.1116,  ..., -0.3179,  0.2235,  0.1840]),\n",
       " 'https://www.wanted.co.kr/wd/167134': tensor([ 0.0258,  0.0194,  0.1455,  ..., -0.2688,  0.2132,  0.1755])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이 중 3개 데이터만 선택해서 테스트해보겠습니다.\n",
    "selected_keys = list(new_embedding_vectors.keys())[:3]\n",
    "selected_data = {key: new_embedding_vectors[key] for key in selected_keys}\n",
    "selected_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame 생성 및 csv 파일 생성\n",
    "col_name = '전체컬럼'\n",
    "\n",
    "df = cos_similarity_df(selected_data)\n",
    "df.to_csv(f\"../data/JobDescription/cosine_cal_{col_name}_test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor를 5등분하여, 하나의 col 혹은 두 개 이상의 col을 선택할 수 있도록 하는 부분입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 0 size: torch.Size([12491, 768])\n",
      "Part 1 size: torch.Size([12491, 768])\n",
      "Part 2 size: torch.Size([12491, 768])\n",
      "Part 3 size: torch.Size([12491, 768])\n",
      "Part 4 size: torch.Size([12491, 768])\n",
      "====================\n",
      "Part 0:\n",
      "tensor([[-0.0482, -0.0684,  0.1829,  ..., -0.2137,  0.1857,  0.1891],\n",
      "        [ 0.0370, -0.0011,  0.1116,  ..., -0.1033,  0.0084,  0.0612],\n",
      "        [ 0.0258,  0.0194,  0.1455,  ..., -0.1985,  0.0530,  0.0386],\n",
      "        ...,\n",
      "        [ 0.0802, -0.0974,  0.1981,  ..., -0.2107,  0.1324,  0.2148],\n",
      "        [ 0.1956, -0.1600,  0.2822,  ..., -0.3600,  0.2164,  0.2478],\n",
      "        [ 0.1956, -0.1600,  0.2822,  ..., -0.3600,  0.2164,  0.2478]])\n",
      "Part 1:\n",
      "tensor([[ 0.0473,  0.0635,  0.0188,  ..., -0.1055,  0.0149, -0.0336],\n",
      "        [-0.1230, -0.1551,  0.1149,  ..., -0.3117,  0.1706,  0.0673],\n",
      "        [ 0.0788, -0.0896,  0.0954,  ..., -0.3110,  0.1475,  0.1109],\n",
      "        ...,\n",
      "        [ 0.2323, -0.0134,  0.1699,  ..., -0.3207,  0.1293,  0.1575],\n",
      "        [ 0.1135,  0.0599,  0.1207,  ..., -0.1289,  0.0667,  0.1798],\n",
      "        [ 0.1135,  0.0599,  0.1207,  ..., -0.1289,  0.0667,  0.1798]])\n",
      "Part 2:\n",
      "tensor([[ 0.0514, -0.1171,  0.1581,  ..., -0.2200,  0.0860,  0.1048],\n",
      "        [ 0.0514, -0.1171,  0.1581,  ..., -0.2200,  0.0860,  0.1048],\n",
      "        [ 0.1355, -0.1327,  0.1246,  ..., -0.3297,  0.1393,  0.2208],\n",
      "        ...,\n",
      "        [ 0.1435, -0.2880,  0.0086,  ..., -0.6831,  0.2713,  0.6174],\n",
      "        [ 0.1588, -0.1902,  0.1886,  ..., -0.4032,  0.1944,  0.1568],\n",
      "        [ 0.1588, -0.1902,  0.1886,  ..., -0.4032,  0.1944,  0.1568]])\n",
      "Part 3:\n",
      "tensor([[ 0.1325, -0.0861,  0.1265,  ..., -0.1409,  0.0519,  0.0862],\n",
      "        [ 0.1329, -0.0863,  0.1265,  ..., -0.1416,  0.0521,  0.0866],\n",
      "        [ 0.0563, -0.0024,  0.1221,  ..., -0.0525,  0.0098,  0.0667],\n",
      "        ...,\n",
      "        [ 0.1919, -0.1017,  0.1646,  ..., -0.1887,  0.2060,  0.1926],\n",
      "        [ 0.2452, -0.3022,  0.2141,  ..., -0.3133,  0.2673,  0.2213],\n",
      "        [ 0.2452, -0.3022,  0.2141,  ..., -0.3133,  0.2673,  0.2213]])\n",
      "Part 4:\n",
      "tensor([[ 0.2179, -0.0415,  0.1543,  ..., -0.2828,  0.1753,  0.2709],\n",
      "        [ 0.0936, -0.0701,  0.0883,  ..., -0.3179,  0.2235,  0.1840],\n",
      "        [-0.0398, -0.0485,  0.2073,  ..., -0.2688,  0.2132,  0.1755],\n",
      "        ...,\n",
      "        [ 0.2014, -0.0464,  0.1524,  ..., -0.3072,  0.1223,  0.2173],\n",
      "        [ 0.1025,  0.0013,  0.1181,  ..., -0.3288,  0.1136,  0.1573],\n",
      "        [ 0.1025,  0.0013,  0.1181,  ..., -0.3288,  0.1136,  0.1573]])\n"
     ]
    }
   ],
   "source": [
    "# 텐서를 5개의 부분으로 나눕니다.\n",
    "tensor_parts = torch.chunk(concatenated_embedding_vectors, chunks=5, dim=1)\n",
    "\n",
    "# 각 부분의 크기 출력 : (torch.Size([12491, 768]))인지 확인\n",
    "for i, part in enumerate(tensor_parts):\n",
    "    print(f\"Part {i} size: {part.size()}\")\n",
    "print(\"====================\")\n",
    "\n",
    "# 나누어진 텐서 확인\n",
    "for i, part in enumerate(tensor_parts):\n",
    "    print(f\"Part {i}:\")\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실제 코드 작업하실 때는 여기 아래부터 수정해주시면 됩니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Tensor Size: torch.Size([12491, 768])\n",
      "Combined Tensor:\n",
      "tensor([[-0.0482, -0.0684,  0.1829,  ..., -0.2137,  0.1857,  0.1891],\n",
      "        [ 0.0370, -0.0011,  0.1116,  ..., -0.1033,  0.0084,  0.0612],\n",
      "        [ 0.0258,  0.0194,  0.1455,  ..., -0.1985,  0.0530,  0.0386],\n",
      "        ...,\n",
      "        [ 0.0802, -0.0974,  0.1981,  ..., -0.2107,  0.1324,  0.2148],\n",
      "        [ 0.1956, -0.1600,  0.2822,  ..., -0.3600,  0.2164,  0.2478],\n",
      "        [ 0.1956, -0.1600,  0.2822,  ..., -0.3600,  0.2164,  0.2478]])\n"
     ]
    }
   ],
   "source": [
    "# ['자격요건', '우대조건', '복지', '회사소개', '주요업무'] 하나씩 분리합니다. 차례대로 part 0,1,2,3,4입니다.\n",
    "# ex) ['자격요건'] 하나를 선택하는 경우 tensor_parts[0]을 입력해주시면 됩니다.\n",
    "one_tensor = tensor_parts[0]\n",
    "\n",
    "# one_tensor 사이즈 확인\n",
    "print(f\"Combined Tensor Size: {one_tensor.size()}\")\n",
    "print(\"Combined Tensor:\")\n",
    "print(one_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Tensor Size: torch.Size([12491, 2304])\n",
      "Combined Tensor:\n",
      "tensor([[-0.0482, -0.0684,  0.1829,  ..., -0.2828,  0.1753,  0.2709],\n",
      "        [ 0.0370, -0.0011,  0.1116,  ..., -0.3179,  0.2235,  0.1840],\n",
      "        [ 0.0258,  0.0194,  0.1455,  ..., -0.2688,  0.2132,  0.1755],\n",
      "        ...,\n",
      "        [ 0.0802, -0.0974,  0.1981,  ..., -0.3072,  0.1223,  0.2173],\n",
      "        [ 0.1956, -0.1600,  0.2822,  ..., -0.3288,  0.1136,  0.1573],\n",
      "        [ 0.1956, -0.1600,  0.2822,  ..., -0.3288,  0.1136,  0.1573]])\n"
     ]
    }
   ],
   "source": [
    "# 2개 이상의 col을 선택할 때 텐서를 합쳐주는 부분입니다. \n",
    "# ex) ['자격요건','주요업무']를 합치는 경우 part 0,4를 합쳐주시면 됩니다.\n",
    "combined_tensor = torch.cat([tensor_parts[0], tensor_parts[1], tensor_parts[4]], dim=1)\n",
    "\n",
    "# combined_tensor 사이즈 확인\n",
    "print(f\"Combined Tensor Size: {combined_tensor.size()}\")\n",
    "print(\"Combined Tensor:\")\n",
    "print(combined_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# 임베딩 벡터에 url을 붙여줍니다.\n",
    "new_embedding_vectors = vector_with_url(여기에 만든 one_tensor OR combined_tensor를 넣어주세요)\n",
    "\n",
    "\n",
    "# DataFrame 생성 및 csv 파일 생성\n",
    "# col_name = '주요업무' <- 실제 작업 시에는 이런 식으로 넣어주세요! \n",
    "col_name = '전체컬럼'\n",
    "\n",
    "df = cos_similarity_df(new_embedding_vectors)\n",
    "df.to_csv(f\"cosine_cal_{col_name}.csv\",index=False)\n",
    "\n",
    "#시간 측정\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "hours = int(execution_time // 3600)\n",
    "minutes = int((execution_time % 3600) // 60)\n",
    "seconds = int(execution_time % 60)\n",
    "print(\"작업 실행 시간: {}시간 {}분 {}초\".format(hours, minutes, seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 병렬계산 방식 추가, 결과 리스트를 만들지 않고 확인하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 병렬계산\n",
    "\n",
    "def cos_sim_cross(vec: torch.tensor):\n",
    "    numerator = torch.mm(vec, vec.T)\n",
    "    root_square_sum_vec = torch.sqrt(torch.sum(torch.square(vec), dim=1, keepdim=True))\n",
    "    denominator = root_square_sum_vec * root_square_sum_vec.T\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 리스트 만드는건데 오래 걸려서 안씀\n",
    "\n",
    "# def make_score_url_list(cos_sim: torch.tensor, url: list):\n",
    "#     result = []\n",
    "#     for row in tqdm(range(len(url))):\n",
    "#         for col in range(row + 1, len(url)):\n",
    "#             result.append((cos_sim[row, col].item(), url[row], url[col]))\n",
    "\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12491])\n"
     ]
    }
   ],
   "source": [
    "cos_sim = cos_sim_cross(combined_tensor)\n",
    "url = pd.read_csv('../data/JobDescription/pre_result.csv')['출처 URL']\n",
    "\n",
    "# 결과를 높은 순으로 정렬\n",
    "cos_sim_argsort = cos_sim.argsort(descending=True, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,  3242,  5987,  ...,  5701,  5375, 11049],\n",
       "        [    1,  1292,  2391,  ...,  1032,  5125,  4771],\n",
       "        [ 1198,  1293,     2,  ...,  6680,  1655,   499],\n",
       "        ...,\n",
       "        [12488,  7978,  8453,  ...,  5701,  5375,  6253],\n",
       "        [12490, 12489, 11492,  ..., 11327, 10818, 11049],\n",
       "        [12489, 12490, 11492,  ..., 11327, 10818, 11049]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0번 공고와 가장 유사한 것은 순서대로 0, 5987, 3242, ......\n",
    "\n",
    "cos_sim_argsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.wanted.co.kr/wd/167134 https://www.wanted.co.kr/wd/167134 https://www.wanted.co.kr/wd/167134\n"
     ]
    }
   ],
   "source": [
    "# 왜 2번 공고와 가장 비슷한 공고가 2번 말고도 1293, 1198 등이 있지?\n",
    "\n",
    "print(url[2], url[1293], url[1198])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기준 url: https://www.wanted.co.kr/wd/167436\n",
      "가장 유사한 10개 공고 (동일 공고 제외)\n",
      "https://www.jumpit.co.kr/position/17437 tensor(0.9733)\n",
      "https://www.wanted.co.kr/wd/127697 tensor(0.9732)\n",
      "https://www.wanted.co.kr/wd/127697 tensor(0.9732)\n",
      "https://www.wanted.co.kr/wd/153609 tensor(0.9727)\n",
      "https://www.jumpit.co.kr/position/13709 tensor(0.9725)\n",
      "https://www.jumpit.co.kr/position/2035 tensor(0.9720)\n",
      "https://www.wanted.co.kr/wd/101462 tensor(0.9717)\n",
      "https://www.wanted.co.kr/wd/160630 tensor(0.9714)\n",
      "https://www.wanted.co.kr/wd/160630 tensor(0.9714)\n",
      "https://www.jumpit.co.kr/position/5028 tensor(0.9712)\n"
     ]
    }
   ],
   "source": [
    "jd_num = 0 # 0 to len(cos_sim_argsort) - 1\n",
    "count = 10\n",
    "\n",
    "print(f'기준 url: {url[jd_num]}')\n",
    "print(f'가장 유사한 {count}개 공고 (동일 공고 제외)')\n",
    "\n",
    "i = 0\n",
    "while count > 0:\n",
    "    obj = cos_sim_argsort[jd_num, i].item()\n",
    "    if url[jd_num] == url[obj]:\n",
    "        i += 1\n",
    "        continue\n",
    "\n",
    "    count -= 1\n",
    "    print(url[obj], cos_sim[jd_num, obj])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기준 url: https://www.wanted.co.kr/wd/167436\n",
      "가장 유사하지 않은 10개 공고 (동일 공고 제외)\n",
      "https://www.jumpit.co.kr/position/16294 tensor(0.0944)\n",
      "https://www.wanted.co.kr/wd/24568 tensor(0.1378)\n",
      "https://www.wanted.co.kr/wd/24568 tensor(0.1378)\n",
      "https://www.wanted.co.kr/wd/24568 tensor(0.1378)\n",
      "https://www.wanted.co.kr/wd/117393 tensor(0.1730)\n",
      "https://www.wanted.co.kr/wd/117393 tensor(0.1730)\n",
      "https://www.wanted.co.kr/wd/130770 tensor(0.1816)\n",
      "https://www.wanted.co.kr/wd/130770 tensor(0.1816)\n",
      "https://www.jobplanet.co.kr/job/search?posting_ids%5B%5D=1245149 tensor(0.2159)\n",
      "https://www.wanted.co.kr/wd/164828 tensor(0.2165)\n"
     ]
    }
   ],
   "source": [
    "jd_num = 0 # 0 to len(cos_sim_argsort) - 1\n",
    "count = 10\n",
    "\n",
    "print(f'기준 url: {url[jd_num]}')\n",
    "print(f'가장 유사하지 않은 {count}개 공고 (동일 공고 제외)')\n",
    "\n",
    "i = len(cos_sim_argsort) - 1\n",
    "while count > 0:\n",
    "    obj = cos_sim_argsort[jd_num, i].item()\n",
    "    if url[jd_num] == url[obj]:\n",
    "        i -= 1\n",
    "        continue\n",
    "\n",
    "    count -= 1\n",
    "    print(url[obj], cos_sim[jd_num, obj])\n",
    "    i -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
