wandb_version: 1

_wandb:
  desc: null
  value:
    python_version: 3.10.12
    cli_version: 0.15.5
    framework: huggingface
    huggingface_version: 4.30.2
    is_jupyter_run: true
    is_kaggle_kernel: true
    start_time: 1689842840.852813
    t:
      1:
      - 1
      - 9
      - 11
      - 41
      - 49
      - 50
      - 55
      2:
      - 1
      - 9
      - 11
      - 41
      - 49
      - 50
      - 55
      3:
      - 2
      - 7
      - 13
      - 23
      4: 3.10.12
      5: 0.15.5
      6: 4.30.2
      8:
      - 1
      - 2
      - 4
      - 5
    m:
    - 1: trainer/global_step
      6:
      - 3
    - 1: train_acc
      5: 1
      6:
      - 1
    - 1: train_loss
      5: 1
      6:
      - 1
    - 1: epoch
      5: 1
      6:
      - 1
    - 1: val_acc
      5: 1
      6:
      - 1
    - 1: val_loss
      5: 1
      6:
      - 1
    - 1: train_avg_acc
      5: 1
      6:
      - 1
    - 1: train_avg_loss
      5: 1
      6:
      - 1
    - 1: val_avg_acc
      5: 1
      6:
      - 1
    - 1: val_avg_loss
      5: 1
      6:
      - 1
    - 1: test_acc
      5: 1
      6:
      - 1
    - 1: test_loss
      5: 1
      6:
      - 1
num_classes:
  desc: null
  value: 10
optimizer:
  desc: null
  value: "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n\
    \    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach:\
    \ None\n    fused: None\n    initial_lr: 2e-05\n    lr: 2e-05\n    maximize: False\n\
    \    weight_decay: 0.01\n)"
lr_scheduler:
  desc: null
  value:
    scheduler: <torch.optim.lr_scheduler.CosineAnnealingWarmRestarts object at 0x2dcc83b20>
    interval: epoch
