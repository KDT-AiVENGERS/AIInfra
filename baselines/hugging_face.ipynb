{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Modules\n",
    "\n",
    "필요한 모듈을 Import 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/jobVS_infra_test/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Modules About Hydra\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "# Modules About Torch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Modules About Pytorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, LightningDataModule\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "\n",
    "# Modules About HuggingFace Transformers\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification, AdamW\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Dataset\n",
    "\n",
    "Custom Dataset을 구성합니다.\n",
    "Data_Module에 있는 CustomDataset을 불러옵니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size: int = 64, data_dir: str = \"./\"):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            # transforms.Normalize((0.1307,), (0.3081,)),\n",
    "            # ViT expects 224x224 images\n",
    "            transforms.Resize((224, 224), antialias=True),\n",
    "            transforms.Lambda(self.repeat_channels)  # ViT expects 3 channels\n",
    "        ])\n",
    "\n",
    "    def repeat_channels(self, x):\n",
    "        return x.repeat(3, 1, 1)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.mnist_train = datasets.MNIST(\n",
    "            self.data_dir, train=True, download=True, transform=self.transform\n",
    "        )\n",
    "        self.mnist_val = datasets.MNIST(\n",
    "            self.data_dir, train=False, download=True, transform=self.transform\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(pl.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.config = config\n",
    "        self.save_hyperparameters()\n",
    "        self.model = ViTForImageClassification.from_pretrained(\n",
    "            \"google/vit-base-patch16-224\")\n",
    "        self.feature_extractor = ViTImageProcessor.from_pretrained(\n",
    "            \"google/vit-base-patch16-224\")\n",
    "\n",
    "    def forward(self, pixel_values, labels=None):\n",
    "        output = self.model(pixel_values=pixel_values, labels=labels)\n",
    "        return output.loss, output.logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        pixel_values = self.feature_extractor(\n",
    "            images=images, return_tensors=\"pt\").pixel_values\n",
    "        loss, logits = self(images, labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        pixel_values = self.feature_extractor(\n",
    "            images=images, return_tensors=\"pt\").pixel_values\n",
    "        loss, logits = self(images, labels)\n",
    "        # loss.requires_grad_(True)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type                      | Params\n",
      "----------------------------------------------------\n",
      "0 | model | ViTForImageClassification | 86.6 M\n",
      "----------------------------------------------------\n",
      "86.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "86.6 M    Total params\n",
      "346.271   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/jobVS_infra_test/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/jobVS_infra_test/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/jobVS_infra_test/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 1/938 [00:02<42:01,  2.69s/it, v_num=21, train_loss=9.330]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/jobVS_infra_test/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:52: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드 및 훈련\n",
    "data_module = MNISTDataModule()\n",
    "config = {}\n",
    "model = MyModel(config=config)\n",
    "trainer = pl.Trainer(max_epochs=1)\n",
    "trainer.fit(model, data_module)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jobVS_infra_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
