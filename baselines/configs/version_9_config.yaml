data:
  batch_size: 64
  data_dir: ./
  pred_batch_size: 32
  train_ratio: 0.6
models:
  CNNModel:
    _target_: __main__.CNNModel
    type: small
sweep:
  early_terminate:
    min_iter: 3
    type: hyperband
  method: bayes
  metric:
    goal: maximize
    name: val_avg_acc
  parameters:
    batch_size:
      values:
      - 32
      - 64
      - 128
    type:
      values:
      - small
      - large
  run_cap: 15
task:
  lr_scheduler:
    interval: epoch
    scheduler:
      T_0: 50
      T_mult: 2
      _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
      verbose: false
  num_classes: 10
  optimizer:
    _target_: torch.optim.AdamW
    lr: 2e-5
train:
  callbacks:
    checkpoint_callback:
      filename: best-model-{epoch:02d}-{val_acc:.2f}
      mode: max
      monitor: val_avg_acc
      save_last: true
      save_top_k: 1
    early_stop_callback:
      min_delta: 0.01
      mode: max
      monitor: val_avg_acc
      patience: 3
      verbose: false
  logger:
    _target_: pytorch_lightning.loggers.WandbLogger
    project: wandb_test
    save_dir: log
  trainer:
    gpus: 2
    max_epochs: 2
