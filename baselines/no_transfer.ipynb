{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Modules\n",
    "\n",
    "필요한 모듈을 Import 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules About Hydra\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "# Modules About Torch, Numpy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Modules About Pytorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, LightningDataModule\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "\n",
    "# Modules About Pandas, Matplotlib, Numpy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Others\n",
    "from typing import List, Any\n",
    "from PIL import Image\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Dataset\n",
    "\n",
    "Custom Dataset을 구성합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.utilities.types import EVAL_DATALOADERS\n",
    "\n",
    "\n",
    "class MNISTDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size: int = 64, data_dir: str = \"./\"):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.predicted_dataloader_attr = None\n",
    "\n",
    "        # Define Transforms\n",
    "        def repeat_channels(x):\n",
    "            return x.repeat(3, 1, 1)\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "            # ViT expects 224x224 images\n",
    "            # transforms.Resize((224, 224), antialias=True),\n",
    "            # transforms.Lambda(repeat_channels)  # ViT expects 3 channels\n",
    "        ])\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # Download MNIST Data\n",
    "        datasets.MNIST(\n",
    "            self.data_dir, train=True, download=True)\n",
    "        datasets.MNIST(\n",
    "            self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        mnist_train = datasets.MNIST(\n",
    "            self.data_dir, train=True, transform=self.transform)\n",
    "        mnist_test = datasets.MNIST(\n",
    "            self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "        # Split Dataset\n",
    "        self.mnist_train, self.mnist_val = random_split(\n",
    "            mnist_train, [55000, 5000])\n",
    "        self.mnist_test = mnist_test\n",
    "\n",
    "    # def _collate_fn(self, samples):\n",
    "    #     이 함수를 사용할 경우\n",
    "    #     DataLoader에 인자로 collate_fn=_collate_fn 를 추가해야합니다.\n",
    "    #     pass\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=self.batch_size)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return self.predict_dataloader_attr\n",
    "\n",
    "    def predict_instantly(self, x: List[Any], y: List[int]):\n",
    "        to_tensor = torchvision.transforms.ToTensor()\n",
    "        tensor_x = torch.stack([to_tensor(item) for item in x])\n",
    "        tensor_y = torch.tensor(y)\n",
    "\n",
    "        return tensor_x, tensor_y\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Model\n",
    "\n",
    "Model 구조를 정의합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(pl.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.config = config\n",
    "        self.id2label = {i: i for i in range(10)}\n",
    "        self.label2id = {i: i for i in range(10)}\n",
    "        self.loss_func = nn.CrossEntropyLoss()\n",
    "        self.model = nn.Sequential(\n",
    "            # Convolutional layer 1\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Convolutional layer 2\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Fully connected layers\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(64 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(64, 10),  # assuming output has 10 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        logits = self.model(x)\n",
    "        loss = self.loss_func(logits, y)\n",
    "        return loss, logits\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Model\n",
    "\n",
    "Task 구조를 정의합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationTask(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        # self.save_hyperparameters()\n",
    "        # self.config = config\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        loss, logits = self.model(x, y)\n",
    "        return loss, logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, acc = self._shared_step(batch)\n",
    "        metrics = {\"train_acc\": acc, \"train_loss\": loss}\n",
    "        self.log_dict(metrics, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    # def on_train_epoch_end(self):\n",
    "    #     pass\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, acc = self._shared_step(batch)\n",
    "        metrics = {\"val_acc\": acc, \"val_loss\": loss}\n",
    "        self.log_dict(metrics, prog_bar=True)\n",
    "\n",
    "    # def on_validation_epoch_end(self):\n",
    "    #     pass\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, acc = self._shared_step(batch)\n",
    "        metrics = {\"test_acc\": acc, \"test_loss\": loss}\n",
    "        self.log_dict(metrics, prog_bar=True)\n",
    "\n",
    "    def _shared_step(self, batch):\n",
    "        x, y = batch\n",
    "        loss, logits = self.model(x, y)\n",
    "        acc_fn = torchmetrics.classification.MulticlassAccuracy(\n",
    "            num_classes=10).to(self.device)\n",
    "        acc = acc_fn(logits, y)\n",
    "        return loss, acc\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        x, y = batch\n",
    "        loss, logits = self.model(x, y)\n",
    "        return loss, logits\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.model.parameters(), lr=2e-5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Model Training을 수행합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type     | Params\n",
      "-----------------------------------\n",
      "0 | model | CNNModel | 429 K \n",
      "-----------------------------------\n",
      "429 K     Trainable params\n",
      "0         Non-trainable params\n",
      "429 K     Total params\n",
      "1.717     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/jobVS_infra_test/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/jobVS_infra_test/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 860/860 [00:30<00:00, 28.52it/s, v_num=121, train_acc=0.750, train_loss=0.654, val_acc=0.823, val_loss=0.698]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 860/860 [00:30<00:00, 28.51it/s, v_num=121, train_acc=0.750, train_loss=0.654, val_acc=0.823, val_loss=0.698]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/jobVS_infra_test/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:03<00:00, 43.13it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Runningstage.testing metric      DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.8261076211929321\n",
      "        test_loss           0.6879092454910278\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드 및 훈련\n",
    "data_module = MNISTDataModule()\n",
    "config = {}\n",
    "models = [CNNModel(config=config)]\n",
    "for model in models:\n",
    "    task = ClassificationTask(model)\n",
    "    trainer = pl.Trainer(max_epochs=1)\n",
    "    trainer.fit(task, data_module)\n",
    "    trainer.test(task, datamodule=data_module)\n",
    "    trainer.save_checkpoint(\"test_checkpoints/best_model.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction\n",
    "\n",
    "직접 Model Prediction을 수행하여 모델이 제대로 동작하는지 검증합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbkElEQVR4nO3df2xV9f3H8dflRy+g7e1KaW8rPyy/jfwwQ6iNynQ0lM4wQEYQ/QMXAsEVM8VfqVHAuayTLc64MNRkA80ElY0f0xg2rLbE2WJACCFuHSV1raMtiONeKLSQ9vP9g693XmnBc7m379vyfCSfpD3nvHvefjz25bn39HN9zjknAAC6WR/rBgAAVycCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACb6WTfwTR0dHTp69KhSU1Pl8/ms2wEAeOSc06lTp5Sbm6s+fbq+z0m6ADp69KiGDRtm3QYA4Ao1NDRo6NChXe5PupfgUlNTrVsAAMTB5X6fJyyA1q1bp+uvv14DBgxQfn6+Pv74429Vx8tuANA7XO73eUIC6M0339TKlSu1evVqffLJJ5o8ebKKiop07NixRJwOANATuQSYNm2aKykpiXzf3t7ucnNzXVlZ2WVrQ6GQk8RgMBiMHj5CodAlf9/H/Q7o3Llz2rdvnwoLCyPb+vTpo8LCQlVVVV10fFtbm8LhcNQAAPR+cQ+gL774Qu3t7crOzo7anp2draampouOLysrUyAQiAyegAOAq4P5U3ClpaUKhUKR0dDQYN0SAKAbxP3vgDIzM9W3b181NzdHbW9ublYwGLzoeL/fL7/fH+82AABJLu53QCkpKZoyZYrKy8sj2zo6OlReXq6CgoJ4nw4A0EMlZCWElStXavHixbr55ps1bdo0vfDCC2ppadGPf/zjRJwOANADJSSAFi5cqOPHj2vVqlVqamrSTTfdpJ07d170YAIA4Orlc8456ya+LhwOKxAIWLcBALhCoVBIaWlpXe43fwoOAHB1IoAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACAiX7WDQCXM2/ePM81f/jDH2I6VyAQiKnOq3/961+ea7Zu3eq55pVXXvFcI0mfffZZTHWAF9wBAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMOFzzjnrJr4uHA5324KQ6H5r1qzxXLNq1SrPNV9++aXnGklqb2+Pqc6rAQMGeK5JTU31XFNbW+u5RpLGjh0bUx3wdaFQSGlpaV3u5w4IAGCCAAIAmIh7AK1Zs0Y+ny9qjB8/Pt6nAQD0cAn5QLobb7xR77333v9O0o/PvQMAREtIMvTr10/BYDARPxoA0Esk5D2gw4cPKzc3VyNHjtR9992n+vr6Lo9ta2tTOByOGgCA3i/uAZSfn6+NGzdq586dWr9+verq6nT77bfr1KlTnR5fVlamQCAQGcOGDYt3SwCAJBT3ACouLtaCBQs0adIkFRUV6d1339XJkyf11ltvdXp8aWmpQqFQZDQ0NMS7JQBAEkr40wHp6ekaO3Zsl38Q5/f75ff7E90GACDJJPzvgE6fPq0jR44oJycn0acCAPQgcQ+gRx99VJWVlfrss8/00Ucfad68eerbt68WLVoU71MBAHqwuL8E9/nnn2vRokU6ceKEhgwZottuu03V1dUaMmRIvE8FAOjBWIwUMRs6dKjnmv3793uuee655zzXvPTSS55rpAsvGXeH4cOHe655+umnPdf86Ec/8lwjSTfccIPnmqamppjOhd6LxUgBAEmJAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACAiYR/IB16rzNnzniuWbt2reeaX//6155rkl19fb3nmq1bt3quuffeez3XSFIwGPRcw2Kk8Io7IACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACZ9zzlk38XXhcFiBQMC6DSDpNDY2eq7JysqK6Vzz5s3zXPOXv/wlpnOh9wqFQkpLS+tyP3dAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATPSzbgDo6QYNGuS55qmnnvJcEwwGPdccP37cc43EwqLoHtwBAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMMFipMDXpKWlea555ZVXPNcsWLDAc01tba3nmoULF3quAboLd0AAABMEEADAhOcA2r17t2bPnq3c3Fz5fD5t3749ar9zTqtWrVJOTo4GDhyowsJCHT58OF79AgB6Cc8B1NLSosmTJ2vdunWd7l+7dq1efPFFvfTSS9qzZ4+uueYaFRUVqbW19YqbBQD0Hp4fQiguLlZxcXGn+5xzeuGFF/TUU09pzpw5kqTXXntN2dnZ2r59u+65554r6xYA0GvE9T2guro6NTU1qbCwMLItEAgoPz9fVVVVnda0tbUpHA5HDQBA7xfXAGpqapIkZWdnR23Pzs6O7PumsrIyBQKByBg2bFg8WwIAJCnzp+BKS0sVCoUio6GhwbolAEA3iGsABYNBSVJzc3PU9ubm5si+b/L7/UpLS4saAIDeL64BlJeXp2AwqPLy8si2cDisPXv2qKCgIJ6nAgD0cJ6fgjt9+nTUkiB1dXU6cOCAMjIyNHz4cD300EP6+c9/rjFjxigvL09PP/20cnNzNXfu3Hj2DQDo4TwH0N69e3XnnXdGvl+5cqUkafHixdq4caMef/xxtbS0aNmyZTp58qRuu+027dy5UwMGDIhf1wCAHs/nnHPWTXxdOBxWIBCwbgNJZPDgwZ5rnn/++ZjO9fU/Ifi2rrnmGs81L7/8suearv74+1Lq6+s91wDxEgqFLvm+vvlTcACAqxMBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwITnj2MAvnLzzTd7rnnyySc913z94z++rVg/Wfejjz7yXFNaWuq55sMPP/RcA/Q23AEBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwwWKk0JIlS2KqW7duneea/v37e67x+Xyea5xznmskKT093XPNxIkTPdeMGTPGc82GDRs81wDJjDsgAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJnwu1lUbEyQcDisQCFi3cVXZvn17THU//OEP49tIF7pzMdJkFss8/OlPf4rpXFu3bvVcs3v3bs81//nPfzzXoOcIhUJKS0vrcj93QAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEywGCl0yy23xFTXr1+/OHcSP3fddZd1C5c0duxYzzV33nmn55ru/G/p+PHjnmv27NnjuebZZ5/1XLN3717PNbhyLEYKAEhKBBAAwITnANq9e7dmz56t3Nxc+Xy+iz5L5v7775fP54sas2bNile/AIBewnMAtbS0aPLkyVq3bl2Xx8yaNUuNjY2RsXnz5itqEgDQ+3h+F7m4uFjFxcWXPMbv9ysYDMbcFACg90vIe0AVFRXKysrSuHHj9MADD+jEiRNdHtvW1qZwOBw1AAC9X9wDaNasWXrttddUXl6u5557TpWVlSouLlZ7e3unx5eVlSkQCETGsGHD4t0SACAJxf0POe65557I1xMnTtSkSZM0atQoVVRUaMaMGRcdX1paqpUrV0a+D4fDhBAAXAUS/hj2yJEjlZmZqdra2k73+/1+paWlRQ0AQO+X8AD6/PPPdeLECeXk5CT6VACAHsTzS3CnT5+Oupupq6vTgQMHlJGRoYyMDD3zzDOaP3++gsGgjhw5oscff1yjR49WUVFRXBsHAPRsngNo7969UWtSffX+zeLFi7V+/XodPHhQr776qk6ePKnc3FzNnDlTzz77rPx+f/y6BgD0eCxGCvQQGRkZnms6e/Dn21i0aJHnmsv9fWBnUlJSPNf897//9VzzyCOPeK6RpFdffTWmOlzAYqQAgKREAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADDBatgA4iKW1brHjh3ruebdd9/1XHP27FnPNZI0btw4zzWnT5+O6Vy9EathAwCSEgEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABP9rBsA0Dt8+eWXnmuqq6s912zdutVzzaJFizzXSNLo0aM91xw4cCCmc12NuAMCAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABggsVIAZgpLS31XLNkyRLPNcePH/dcI7GwaKJxBwQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEi5ECuIjf7/dc88QTT3iueeyxxzzXOOc81+zZs8dzDRKPOyAAgAkCCABgwlMAlZWVaerUqUpNTVVWVpbmzp2rmpqaqGNaW1tVUlKiwYMH69prr9X8+fPV3Nwc16YBAD2fpwCqrKxUSUmJqqurtWvXLp0/f14zZ85US0tL5JiHH35Yb7/9trZs2aLKykodPXpUd999d9wbBwD0bJ4eQti5c2fU9xs3blRWVpb27dun6dOnKxQK6fe//702bdqk73//+5KkDRs26IYbblB1dbVuueWW+HUOAOjRrug9oFAoJEnKyMiQJO3bt0/nz59XYWFh5Jjx48dr+PDhqqqq6vRntLW1KRwORw0AQO8XcwB1dHTooYce0q233qoJEyZIkpqampSSkqL09PSoY7Ozs9XU1NTpzykrK1MgEIiMYcOGxdoSAKAHiTmASkpKdOjQIb3xxhtX1EBpaalCoVBkNDQ0XNHPAwD0DDH9IeqKFSv0zjvvaPfu3Ro6dGhkezAY1Llz53Ty5Mmou6Dm5mYFg8FOf5bf74/pj94AAD2bpzsg55xWrFihbdu26f3331deXl7U/ilTpqh///4qLy+PbKupqVF9fb0KCgri0zEAoFfwdAdUUlKiTZs2aceOHUpNTY28rxMIBDRw4EAFAgEtWbJEK1euVEZGhtLS0vTggw+qoKCAJ+AAAFE8BdD69eslSXfccUfU9g0bNuj++++XJP3mN79Rnz59NH/+fLW1tamoqEi/+93v4tIsAKD38LlYVvZLoHA4rEAgYN0GkshNN93kuebcuXMxnevTTz+Nqc6r2267zXPN4MGDPddMnDjRc40k3XXXXZ5rpk2bFtO5vPrb3/7muWbBggUxnev06dMx1eGCUCiktLS0LvezFhwAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwERMn4gKdKePPvrIc017e3tM5zp79mxMdV5daoXgrqSkpHiu6c7F7vfu3eu55he/+IXnmr/+9a+ea1pbWz3XIPG4AwIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCxUiR9Orr6z3XjBkzJqZzDRo0KKa6ZPXnP/85prqtW7d2y7nOnz/vuQa9B3dAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATLAYKZLe+PHjrVsAkADcAQEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwISnACorK9PUqVOVmpqqrKwszZ07VzU1NVHH3HHHHfL5fFFj+fLlcW0aANDzeQqgyspKlZSUqLq6Wrt27dL58+c1c+ZMtbS0RB23dOlSNTY2RsbatWvj2jQAoOfz9ImoO3fujPp+48aNysrK0r59+zR9+vTI9kGDBikYDManQwBAr3RF7wGFQiFJUkZGRtT2119/XZmZmZowYYJKS0t15syZLn9GW1ubwuFw1AAAXAVcjNrb291dd93lbr311qjtL7/8stu5c6c7ePCg++Mf/+iuu+46N2/evC5/zurVq50kBoPBYPSyEQqFLpkjMQfQ8uXL3YgRI1xDQ8MljysvL3eSXG1tbaf7W1tbXSgUioyGhgbzSWMwGAzGlY/LBZCn94C+smLFCr3zzjvavXu3hg4deslj8/PzJUm1tbUaNWrURfv9fr/8fn8sbQAAejBPAeSc04MPPqht27apoqJCeXl5l605cOCAJCknJyemBgEAvZOnACopKdGmTZu0Y8cOpaamqqmpSZIUCAQ0cOBAHTlyRJs2bdIPfvADDR48WAcPHtTDDz+s6dOna9KkSQn5BwAA9FBe3vdRF6/zbdiwwTnnXH19vZs+fbrLyMhwfr/fjR492j322GOXfR3w60KhkPnrlgwGg8G48nG53/2+/w+WpBEOhxUIBKzbAABcoVAopLS0tC73sxYcAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMBE0gWQc866BQBAHFzu93nSBdCpU6esWwAAxMHlfp/7XJLdcnR0dOjo0aNKTU2Vz+eL2hcOhzVs2DA1NDQoLS3NqEN7zMMFzMMFzMMFzMMFyTAPzjmdOnVKubm56tOn6/ucft3Y07fSp08fDR069JLHpKWlXdUX2FeYhwuYhwuYhwuYhwus5yEQCFz2mKR7CQ4AcHUggAAAJnpUAPn9fq1evVp+v9+6FVPMwwXMwwXMwwXMwwU9aR6S7iEEAMDVoUfdAQEAeg8CCABgggACAJgggAAAJnpMAK1bt07XX3+9BgwYoPz8fH388cfWLXW7NWvWyOfzRY3x48dbt5Vwu3fv1uzZs5Wbmyufz6ft27dH7XfOadWqVcrJydHAgQNVWFiow4cP2zSbQJebh/vvv/+i62PWrFk2zSZIWVmZpk6dqtTUVGVlZWnu3LmqqamJOqa1tVUlJSUaPHiwrr32Ws2fP1/Nzc1GHSfGt5mHO+6446LrYfny5UYdd65HBNCbb76plStXavXq1frkk080efJkFRUV6dixY9atdbsbb7xRjY2NkfHhhx9at5RwLS0tmjx5statW9fp/rVr1+rFF1/USy+9pD179uiaa65RUVGRWltbu7nTxLrcPEjSrFmzoq6PzZs3d2OHiVdZWamSkhJVV1dr165dOn/+vGbOnKmWlpbIMQ8//LDefvttbdmyRZWVlTp69Kjuvvtuw67j79vMgyQtXbo06npYu3atUcddcD3AtGnTXElJSeT79vZ2l5ub68rKygy76n6rV692kydPtm7DlCS3bdu2yPcdHR0uGAy6X/3qV5FtJ0+edH6/323evNmgw+7xzXlwzrnFixe7OXPmmPRj5dixY06Sq6ysdM5d+Hffv39/t2XLlsgx//jHP5wkV1VVZdVmwn1zHpxz7nvf+5776U9/atfUt5D0d0Dnzp3Tvn37VFhYGNnWp08fFRYWqqqqyrAzG4cPH1Zubq5Gjhyp++67T/X19dYtmaqrq1NTU1PU9REIBJSfn39VXh8VFRXKysrSuHHj9MADD+jEiRPWLSVUKBSSJGVkZEiS9u3bp/Pnz0ddD+PHj9fw4cN79fXwzXn4yuuvv67MzExNmDBBpaWlOnPmjEV7XUq6xUi/6YsvvlB7e7uys7OjtmdnZ+uf//ynUVc28vPztXHjRo0bN06NjY165plndPvtt+vQoUNKTU21bs9EU1OTJHV6fXy172oxa9Ys3X333crLy9ORI0f05JNPqri4WFVVVerbt691e3HX0dGhhx56SLfeeqsmTJgg6cL1kJKSovT09Khje/P10Nk8SNK9996rESNGKDc3VwcPHtQTTzyhmpoabd261bDbaEkfQPif4uLiyNeTJk1Sfn6+RowYobfeektLliwx7AzJ4J577ol8PXHiRE2aNEmjRo1SRUWFZsyYYdhZYpSUlOjQoUNXxfugl9LVPCxbtizy9cSJE5WTk6MZM2boyJEjGjVqVHe32amkfwkuMzNTffv2vegplubmZgWDQaOukkN6errGjh2r2tpa61bMfHUNcH1cbOTIkcrMzOyV18eKFSv0zjvv6IMPPoj6+JZgMKhz587p5MmTUcf31uuhq3noTH5+viQl1fWQ9AGUkpKiKVOmqLy8PLKto6ND5eXlKigoMOzM3unTp3XkyBHl5ORYt2ImLy9PwWAw6voIh8Pas2fPVX99fP755zpx4kSvuj6cc1qxYoW2bdum999/X3l5eVH7p0yZov79+0ddDzU1Naqvr+9V18Pl5qEzBw4ckKTkuh6sn4L4Nt544w3n9/vdxo0b3aeffuqWLVvm0tPTXVNTk3Vr3eqRRx5xFRUVrq6uzv397393hYWFLjMz0x07dsy6tYQ6deqU279/v9u/f7+T5J5//nm3f/9+9+9//9s559wvf/lLl56e7nbs2OEOHjzo5syZ4/Ly8tzZs2eNO4+vS83DqVOn3KOPPuqqqqpcXV2de++999x3v/tdN2bMGNfa2mrdetw88MADLhAIuIqKCtfY2BgZZ86ciRyzfPlyN3z4cPf++++7vXv3uoKCAldQUGDYdfxdbh5qa2vdz372M7d3715XV1fnduzY4UaOHOmmT59u3Hm0HhFAzjn329/+1g0fPtylpKS4adOmuerqauuWut3ChQtdTk6OS0lJcdddd51buHChq62ttW4r4T744AMn6aKxePFi59yFR7Gffvppl52d7fx+v5sxY4arqamxbToBLjUPZ86ccTNnznRDhgxx/fv3dyNGjHBLly7tdf+T1tk/vyS3YcOGyDFnz551P/nJT9x3vvMdN2jQIDdv3jzX2Nho13QCXG4e6uvr3fTp011GRobz+/1u9OjR7rHHHnOhUMi28W/g4xgAACaS/j0gAEDvRAABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwMT/AVzd0QjLKoVyAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 3, Predicted label: 3\n"
     ]
    }
   ],
   "source": [
    "data_module = MNISTDataModule()\n",
    "# MNIST 테스트 데이터셋 로드\n",
    "predict_dataset = datasets.MNIST(\n",
    "    root='./', train=False, download=True)\n",
    "\n",
    "# 랜덤 이미지 선택\n",
    "random_idx = torch.randint(len(predict_dataset), size=(1,)).item()\n",
    "image, true_label = predict_dataset[random_idx]\n",
    "\n",
    "# 이미지 확인 (optional)\n",
    "transform = torchvision.transforms.ToTensor()\n",
    "image_tensor = transform(image)\n",
    "plt.imshow(image_tensor[0].squeeze(), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 모델 생성 및 학습된 가중치 로드\n",
    "model_config = {}\n",
    "model = ClassificationTask.load_from_checkpoint(\n",
    "    \"test_checkpoints/best_model.ckpt\", model=CNNModel(config=model_config))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x, y = data_module.predict_instantly([image], [true_label])\n",
    "    loss, logits = model(x, y)\n",
    "\n",
    "# Predict Data를 원하는 DataLoader로 직접 만들어서 predict를 수행하고자 할 경우\n",
    "# data_module.predicted_dataloader_attr = your_dataloader\n",
    "# trainer = pl.Trainer()\n",
    "# loss, logits = trainer.predict(model, datamodule=data_module)\n",
    "\n",
    "\n",
    "# 가장 높은 확률을 가진 클래스 예측\n",
    "_, predicted_class = torch.max(logits, dim=1)\n",
    "\n",
    "print(f'True label: {true_label}, Predicted label: {predicted_class.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jobVS_infra_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
