# defaults:
#   - override hydra/sweeper: optuna

# hydra/sweeper/optuna:
#   optuna_config:
#     n_trials: 40
#     direction: maximize
#     storage: null
#     study_name: tpe
#     n_jobs: 1
#     seed: 123

member_name: eui-jin

data:
  data_dir: "./"
  batch_size: 64
  pred_batch_size: 32
  train_ratio: 0.6

models:
  CNNModel:
    _target_: "__main__.CNNModel"
    type: small

task:
  num_classes: 10
  optimizer:
    _target_: "torch.optim.AdamW"
    lr: 2e-5
  lr_scheduler:
    scheduler:
      _target_: "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts"
      T_0: 50
      T_mult: 2
      verbose: False

    interval: epoch

train:
  callbacks:
    checkpoint_callback:
      monitor: "val_avg_acc"
      # dirpath: "checkpoints/checkpoints/"
      filename: "best-model-{epoch:02d}-{val_acc:.2f}"
      save_top_k: 1
      save_last: True
      mode: "max"
    early_stop_callback:
      monitor: "val_avg_acc"
      min_delta: 0.01
      patience: 3
      verbose: False
      mode: "max"

  logger:
    # ----- tensorboard -----
    # _target_: pytorch_lightning.loggers.TensorBoardLogger
    # save_dir: tb_logs
    # name: my_model
    # ----- Wandb -----
    _target_: pytorch_lightning.loggers.WandbLogger
    save_dir: log
    # name: my_model_5
    project: wandb_test

  max_epochs: 2
